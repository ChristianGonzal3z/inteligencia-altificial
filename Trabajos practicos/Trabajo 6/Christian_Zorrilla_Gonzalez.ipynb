{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica #6\n",
    "\n",
    "## Nombre: Christian Zorrilla Gonzalez\n",
    "\n",
    "## Matrícula: 21-SISN-2-070\n",
    "\n",
    "## Fecha de entrega: 18 de Octubre de 2023\n",
    "\n",
    "## Frases e imágenes\n",
    "\n",
    "Utilizando una interfaz Gradio, crear una aplicación que reciba una entrada de texto y, al ejecutarlo, devuelva una frase relacionada y una imagen.\n",
    "\n",
    "Ejemplo: si introducimos \"guerra\", debe mostrar una imagen relacionada con la guerra y una frase sobre este tema.\n",
    "\n",
    "## Traductor\n",
    "\n",
    "Utilizando una interfaz Gradio, crear una aplicación que reciba una entrada de texto y lo traduzca a uno de los idiomas disponibles en una lista. La traducción debe realizarse sin agregar nada más. La lista debe contener al menos 5 idiomas.\n",
    "\n",
    "Ejemplo: si la entrada es \"Watashi wa michi to shinri to inochi desu\" y se selecciona el idioma español, debe devolver únicamente: \"Yo soy el camino, la verdad y la vida\", sin agregar nada más.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traductor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import torch\n",
    "\n",
    "# this model was loaded from https://hf.co/models\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "LANGS = [\"ace_Arab\", \"eng_Latn\", \"fra_Latn\", \"spa_Latn\"]\n",
    "\n",
    "def translate(text, src_lang, tgt_lang):\n",
    "    \"\"\"\n",
    "    Translate the text from source lang to target lang\n",
    "    \"\"\"\n",
    "    translation_pipeline = pipeline(\"translation\", model=model, tokenizer=tokenizer, src_lang=src_lang, tgt_lang=tgt_lang, max_length=400, device=device)\n",
    "    result = translation_pipeline(text)\n",
    "    return result[0]['translation_text']\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=translate,\n",
    "    inputs=[\n",
    "        gr.components.Textbox(label=\"Text\"),\n",
    "        gr.components.Dropdown(label=\"Source Language\", choices=LANGS),\n",
    "        gr.components.Dropdown(label=\"Target Language\", choices=LANGS),\n",
    "    ],\n",
    "    outputs=[\"text\"],\n",
    "    examples=[[\"Building a translation demo with Gradio is so easy!\", \"eng_Latn\", \"spa_Latn\"]],\n",
    "    cache_examples=False,\n",
    "    title=\"Translation Demo\",\n",
    "    description=\"This demo is a simplified version of the original [NLLB-Translator](https://huggingface.co/spaces/Narrativaai/NLLB-Translator) space\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "def obtener_imagen(palabra_clave):\n",
    "    api_key = \"e60807c3ce9c46e1a0e1eedc5f2a7dc8\"\n",
    "    endpoint = \"https://api.cognitive.microsoft.com/bing/v7.0/images/search\"\n",
    "\n",
    "    try:\n",
    "        headers = {\"Ocp-Apim-Subscription-Key\": api_key}\n",
    "        params = {\"q\": palabra_clave, \"count\": 1}\n",
    "        response = requests.get(endpoint, headers=headers, params=params)\n",
    "        data = response.json()\n",
    "        imagen_url = data[\"value\"][0][\"contentUrl\"]\n",
    "        imagen_resp = requests.get(imagen_url)\n",
    "        imagen = Image.open(BytesIO(imagen_resp.content))\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching image: {e}\")\n",
    "        imagen = None\n",
    "\n",
    "    return imagen\n",
    "\n",
    "def generar_frase(palabra_clave):\n",
    "    frase = f\"Una imagen relacionada a '{palabra_clave}'\"\n",
    "    return frase\n",
    "\n",
    "interfaz = gr.Interface(\n",
    "    fn=lambda texto: (obtener_imagen(texto), generar_frase(texto)),\n",
    "    inputs=\"text\",\n",
    "    outputs=[\"image\", \"text\"],\n",
    "    layout=\"vertical\",\n",
    "    examples=[[\"guerra\"]]\n",
    ")\n",
    "\n",
    "interfaz.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
