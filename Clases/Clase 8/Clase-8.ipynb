{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning (Aprendizaje Profundo)\n",
    "---\n",
    "<style>\n",
    "      h1, h2, h3, h4, h5, h6,.imagen {\n",
    "        text-align: center;\n",
    "      }\n",
    " img{width: 75%; height: 75%;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- [Deep Learning (Aprendizaje Profundo)](#deep-learning-aprendizaje-profundo)\n",
    "  - [Es o no es una pizza](#es-o-no-es-una-pizza)\n",
    "  - [Neuronas](#neuronas)\n",
    "    - [Estructura de una neurona](#estructura-de-una-neurona)\n",
    "  - [Neuronas artificiales](#neuronas-artificiales)\n",
    "    - [Estructura de una neurona artificial](#estructura-de-una-neurona-artificial)\n",
    "      - [Funciones de activación](#funciones-de-activación)\n",
    "        - [Función Sigmoide (Sigmoid)](#función-sigmoide-sigmoid)\n",
    "        - [Función ReLU (Rectified Linear Unit)](#función-relu-rectified-linear-unit)\n",
    "        - [Función Leaky ReLU](#función-leaky-relu)\n",
    "        - [Función Tanh (Tangente hiperbólica)](#función-tanh-tangente-hiperbólica)\n",
    "        - [Función Identidad (Linear)](#función-identidad-linear)\n",
    "  - [Redes neuronales artificiales](#redes-neuronales-artificiales)\n",
    "    - [Arquitecturas](#arquitecturas)\n",
    "      - [Perceptrón](#perceptrón)\n",
    "      - [Redes Neuronales Feedforward](#redes-neuronales-feedforward)\n",
    "      - [Redes Neuronales Recurrentes (RNN)](#redes-neuronales-recurrentes-rnn)\n",
    "      - [Redes neuronales convolucionales (ConvNets o CNN)](#redes-neuronales-convolucionales-convnets-o-cnn)\n",
    "      - [Variational Autoencoder (VAE)](#variational-autoencoder-vae)\n",
    "      - [UNET](#unet)\n",
    "      - [Transformer](#transformer)\n",
    "    - [Deep Learning](#deep-learning)\n",
    "    - [Entrenamiento de una red neuronal](#entrenamiento-de-una-red-neuronal)\n",
    "      - [pytorch](#pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Es o no es una pizza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar librerías \n",
    "\n",
    "```jupyterpython\n",
    "%pip install torch torchvision datasets matplotlib sklearn pandas tqdm\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos\n",
    "\n",
    "```python\n",
    " \n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Cargamos el conjunto de datos \"pizza_not_pizza\" con la partición \"train\"\n",
    "dataset = load_dataset(\"nateraw/pizza_not_pizza\", split=\"train\")\n",
    "\n",
    "# Mezclamos aleatoriamente los datos en el conjunto de datos\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# Convertimos el conjunto de datos a un objeto Pandas DataFrame\n",
    "dataset = dataset.to_pandas()\n",
    "\n",
    "# Mostramos las primeras filas del DataFrame\n",
    "dataset.head()\n",
    "\n",
    "# Seleccionamos aleatoriamente el 80% de los datos para el conjunto de entrenamiento\n",
    "train = dataset.sample(frac=0.8)\n",
    "\n",
    "# Eliminamos los datos seleccionados para el conjunto de entrenamiento del conjunto de datos original para obtener el conjunto de prueba\n",
    "test = dataset.drop(train.index)\n",
    "\n",
    "#visualizamos una imagen\n",
    "Image.open(dataset['image'][4]['path']).resize((256,256))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones\n",
    "\n",
    "```python\n",
    "# Importamos la función transforms del módulo torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Definimos los valores de media, desviación estándar y tamaño de imagen\n",
    "media = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "size = 192\n",
    "\n",
    "# Definimos la transformación para el conjunto de entrenamiento\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize([size, size]),  # Redimensionamos la imagen a tamaño 192x192\n",
    "    transforms.ToTensor(),  # Convertimos la imagen a un tensor\n",
    "    transforms.Normalize(media, std)  # Normalizamos los valores de los píxeles de la imagen\n",
    "])\n",
    "\n",
    "# Definimos la transformación para el conjunto de prueba\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize([size, size]),  # Redimensionamos la imagen a tamaño 192x192\n",
    "    transforms.ToTensor(),  # Convertimos la imagen a un tensor\n",
    "    transforms.Normalize(media, std)  # Normalizamos los valores de los píxeles de la imagen\n",
    "])\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "```python\n",
    "# Importamos la clase Dataset del módulo torch.utils.data\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PizzaNotPizzaDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe.values  # Convertimos el DataFrame a un arreglo de Numpy\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)  # Devuelve la longitud del arreglo\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.dataframe[idx][0]['path'])  # Abrimos la imagen utilizando la ruta de la imagen en el DataFrame\n",
    "        label = self.dataframe[idx][1]  # Obtenemos la etiqueta de la imagen\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Aplicamos la transformación a la imagen si se especificó\n",
    "            \n",
    "        return image, label  # Devolvemos la imagen y su etiqueta como una tupla\n",
    "\n",
    "# Creamos un objeto de la clase PizzaNotPizzaDataset para el conjunto de entrenamiento\n",
    "train_dataset = PizzaNotPizzaDataset(train, transform=train_transform)\n",
    "\n",
    "# Creamos un objeto de la clase PizzaNotPizzaDataset para el conjunto de prueba\n",
    "test_dataset = PizzaNotPizzaDataset(test, transform=test_transform)\n",
    "\n",
    "# Obtenemos la primera imagen y su etiqueta del conjunto de entrenamiento\n",
    "imagen, etiqueta = train_dataset[0]\n",
    "\n",
    "# Mostramos la forma de la imagen y su etiqueta\n",
    "imagen.shape, etiqueta\n",
    "\n",
    "```\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders\n",
    "\n",
    "```python\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Definimos el tamaño del lote (batch size) como 32\n",
    "bs = 32\n",
    "\n",
    "# Creamos un objeto DataLoader para el conjunto de entrenamiento\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "# Creamos un objeto DataLoader para el conjunto de prueba\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "\n",
    "# Obtenemos un lote de datos de entrenamiento utilizando el objeto DataLoader\n",
    "btest = iter(train_dataloader).next()\n",
    "\n",
    "# Definimos la cantidad de imágenes que se mostrarán, así como el número de filas y columnas en la figura\n",
    "cantidad = 20\n",
    "filas = 4\n",
    "columnas = 5\n",
    "\n",
    "# Convertimos los valores de media y desviación estándar a tensores de PyTorch\n",
    "tensormedia = torch.tensor(media)\n",
    "tensorstd = torch.tensor(std)\n",
    "\n",
    "# Creamos una figura con subfiguras utilizando la función subplots() de pyplot\n",
    "fig, axs = plt.subplots(filas, columnas, figsize=(15, 10))\n",
    "\n",
    "# Iteramos sobre las imágenes en el lote y las mostramos en las subfiguras\n",
    "for i in range(cantidad):\n",
    "    ax = axs[i//columnas, i%columnas]\n",
    "    ax.imshow(btest[0][i].permute(1,2,0)*tensorstd+tensormedia )  # Mostramos la imagen con los valores de píxeles normalizados\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"pizza\" if btest[1][i].item()==1 else \"not pizza\")  # Mostramos la etiqueta de la imagen como título de la subfigura\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "\n",
    "```python\n",
    "# Importamos el módulo models del paquete torchvision y el módulo nn de PyTorch\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "# Definimos la clase PizzaNotPizzaModel que hereda de la clase nn.Module\n",
    "class PizzaNotPizzaModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Cargamos el modelo ResNet18 pre-entrenado en ImageNet y congelamos sus parámetros\n",
    "        self.model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1, progress=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Modificamos la capa completamente conectada (fc) del modelo para adaptarlo a nuestro problema\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(self.model.fc.in_features, 512),  # Añadimos una capa lineal con 512 neuronas\n",
    "            nn.ReLU(inplace=True),  # Añadimos una función de activación ReLU\n",
    "            nn.Dropout(0.2),  # Añadimos una capa de dropout con una probabilidad de 0.2\n",
    "            nn.Linear(512, num_classes)  # Añadimos una capa lineal con el número de clases de nuestro problema\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Devolvemos la salida del modelo para una entrada x\n",
    "\n",
    "# Creamos un objeto de la clase PizzaNotPizzaModel con 2 clases de salida\n",
    "modelo = PizzaNotPizzaModel(2)\n",
    "\n",
    "# Pasamos un lote de datos de entrenamiento al modelo y obtenemos la salida\n",
    "modelo(btest[0])\n",
    "\n",
    "```\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros y metricas\n",
    "\n",
    "```python\n",
    "# Creamos un objeto de dispositivo que utiliza la GPU si está disponible, de lo contrario utiliza la CPU\n",
    "dispositivo = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Mostramos el dispositivo utilizado\n",
    "print(dispositivo)\n",
    "\n",
    "# Definimos la tasa de aprendizaje y el número de épocas\n",
    "lr = 3e-3\n",
    "epocas = 5\n",
    "\n",
    "# Creamos un objeto de la clase PizzaNotPizzaModel y lo movemos al dispositivo especificado\n",
    "modelo = PizzaNotPizzaModel(2)\n",
    "modelo.to(dispositivo)\n",
    "\n",
    "# Definimos la función de pérdida y el optimizador\n",
    "funciondeperdida = nn.CrossEntropyLoss()\n",
    "optimizador = torch.optim.SGD(modelo.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "\n",
    "# Definimos las listas para almacenar las métricas de entrenamiento y prueba\n",
    "perdidas_train = []  # Lista para almacenar las pérdidas de entrenamiento\n",
    "perdidas_test = []  # Lista para almacenar las pérdidas de prueba\n",
    "\n",
    "error_train = []  # Lista para almacenar los errores de entrenamiento\n",
    "error_test = []  # Lista para almacenar los errores de prueba\n",
    "\n",
    "Acuracy_train = []  # Lista para almacenar las precisiones de entrenamiento\n",
    "Acuracy_test = []  # Lista para almacenar las precisiones de prueba\n",
    "\n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucle de entrenamiento\n",
    "\n",
    "```python\n",
    "# Iteramos sobre el número de épocas especificado\n",
    "for epoca in (range(epocas)):\n",
    "    # Ponemos el modelo en modo de entrenamiento\n",
    "    modelo.train()\n",
    "    \n",
    "    # Inicializamos las variables de pérdida, precisión y error para el conjunto de entrenamiento\n",
    "    perdida_train = 0\n",
    "    acuracy_train = 0\n",
    "    error  = 0\n",
    "    \n",
    "    # Iteramos sobre los lotes de datos de entrenamiento\n",
    "    for imagenes, etiquetas in tqdm(train_dataloader):\n",
    "        # Movemos los datos al dispositivo especificado\n",
    "        imagenes = imagenes.to(dispositivo)\n",
    "        etiquetas = etiquetas.to(dispositivo)\n",
    "        \n",
    "        # Reiniciamos los gradientes del optimizador\n",
    "        optimizador.zero_grad()\n",
    "        \n",
    "        # Hacemos una predicción con el modelo\n",
    "        predicciones = modelo(imagenes) \n",
    "        \n",
    "        # Calculamos la pérdida\n",
    "        perdida = funciondeperdida(predicciones, etiquetas )\n",
    "        \n",
    "        # Calculamos los gradientes y actualizamos los parámetros del modelo\n",
    "        perdida.backward()\n",
    "        optimizador.step()\n",
    "        \n",
    "        # Calculamos la precisión y el error para el lote actual\n",
    "        _, predicciones = torch.max(predicciones, 1)\n",
    "        perdida_train += perdida.item()\n",
    "        acuracy_train += torch.sum(predicciones == etiquetas).item() / len(etiquetas)\n",
    "        error += torch.sum(predicciones != etiquetas).item() / len(etiquetas)\n",
    "        \n",
    "    # Calculamos la pérdida, precisión y error promedio para el conjunto de entrenamiento\n",
    "    perdida_train /= len(train_dataloader)\n",
    "    acuracy_train /= len(train_dataloader )\n",
    "    error /= len(train_dataloader )\n",
    "    \n",
    "    # Almacenamos las métricas de entrenamiento en las listas correspondientes\n",
    "    perdidas_train.append(perdida_train)\n",
    "    Acuracy_train.append(acuracy_train)\n",
    "    error_train.append(error)\n",
    "    \n",
    "    # Ponemos el modelo en modo de evaluación\n",
    "    modelo.eval()\n",
    "    \n",
    "    # Inicializamos las variables de pérdida, precisión y error para el conjunto de prueba\n",
    "    perdida_test = 0\n",
    "    acuracy_test = 0\n",
    "    error  = 0\n",
    "    \n",
    "    # Iteramos sobre los lotes de datos de prueba\n",
    "    for imagenes, etiquetas in tqdm(test_dataloader):\n",
    "        # Movemos los datos al dispositivo especificado\n",
    "        imagenes = imagenes.to(dispositivo)\n",
    "        etiquetas = etiquetas.to(dispositivo)\n",
    "        \n",
    "        # Desactivamos el cálculo de gradientes para acelerar la inferencia\n",
    "        with torch.no_grad():\n",
    "            # Hacemos una predicción con el modelo\n",
    "            predicciones = modelo(imagenes)\n",
    "            \n",
    "            # Calculamos la pérdida\n",
    "            perdida = funciondeperdida(predicciones, etiquetas )\n",
    "            perdida_test += perdida.item()\n",
    "            \n",
    "            # Calculamos la precisión y el error para el lote actual\n",
    "            _, predicciones = torch.max(predicciones, 1)\n",
    "            acuracy_test += torch.sum(predicciones == etiquetas).item() / len(etiquetas)\n",
    "            error+= torch.sum(predicciones != etiquetas).item() / len(etiquetas)\n",
    "    \n",
    "    # Calculamos la pérdida, precisión y error promedio para el conjunto de prueba\n",
    "    perdida_test /= len(test_dataloader )\n",
    "    acuracy_test /= len(test_dataloader )\n",
    "    error /= len(test_dataloader )\n",
    "    \n",
    "    # Almacenamos las métricas de prueba en las listas correspondientes\n",
    "    perdidas_test.append(perdida_test)\n",
    "    Acuracy_test.append(acuracy_test)\n",
    "    error_test.append(error)\n",
    "    \n",
    "    # Imprimimos las métricas de entrenamiento y prueba para la época actual\n",
    "    print(f\"Epoca {epoca+1}/{epocas}, perdida train: {perdidas_train[-1]}, perdida test: {perdidas_test[-1]}, acuracy train: {Acuracy_train[-1]}, acuracy test: {Acuracy_test[-1]}, error train: {error_train[-1]}, error test: {error_test[-1]}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficas\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gráfica de pérdidas\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(perdidas_train, label='train')\n",
    "plt.plot(perdidas_test, label='test')\n",
    "plt.legend()\n",
    "plt.title('Pérdidas')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.show()\n",
    "\n",
    "# Gráfica de precisión\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(Acuracy_train, label='train')\n",
    "plt.plot(Acuracy_test, label='test')\n",
    "plt.legend()\n",
    "plt.title('Precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.show()\n",
    "\n",
    "# Gráfica de error\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(error_train, label='train')\n",
    "plt.plot(error_test, label='test')\n",
    "plt.legend()\n",
    "plt.title('Error')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones\n",
    "\n",
    "```python\n",
    "# Predecir desde una URL de imagen aleatoria\n",
    "import requests\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Lista de URLs de imágenes\n",
    "urls = [\n",
    "    \"https://whatnowhou.com/wp-content/uploads/sites/17/2022/08/Crown-Pizza-to-Open-in-Katy-Photo-1.jpg\",\n",
    "    \"https://www.gardengourmet.com/sites/default/files/recipes/83393badc124840730cb91e3cd839b93_220516_gg_q3_recipe_hotdogs_v3.jpg\",\n",
    "    \"https://img.sndimg.com/food/image/upload/q_92,fl_progressive,w_1200,c_scale/v1/img/recipes/91/82/7/pic74ikYM.jpg\",\n",
    "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRm80awe9utbx2ShDIu-PxcArRkKm2BCq4vWA&usqp=CAU\",\n",
    "    \"https://uploads-ssl.webflow.com/5e9ebc3fff165933f19fbdbe/61b31c9d289e22335b6753b2_Ice%20Cream%202.jpg\",\n",
    "    \"https://food.fnr.sndimg.com/content/dam/images/food/fullset/2015/5/14/2/YW0611H_Taco-Pizza_s4x3.jpg.rend.hgtvcom.616.462.suffix/1433264087767.jpeg\",\n",
    "    \"https://www.favfamilyrecipes.com/wp-content/uploads/2022/08/Taco-Pizza-toppings.jpg\",\n",
    "    \"https://hoy.com.do/wp-content/uploads/2022/07/ROM_5409.jpg\",\n",
    "    \"https://previews.123rf.com/images/igormalovic/igormalovic1604/igormalovic160400468/55349527-ni%C3%B1a-en-la-ilustraci%C3%B3n-de-dibujos-animados-vestido-de-color-rosa.jpg\",\n",
    "    \"https://m.media-amazon.com/images/I/61DtAEkJBEL._AC_UF894,1000_QL80_.jpg\"\n",
    "]\n",
    "\n",
    "# Elegir una URL aleatoria de la lista\n",
    "url = random.choice(urls)\n",
    "\n",
    "# Descargar la imagen de la URL y abrirla con la clase Image de PIL\n",
    "imagen = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# Aplicar la transformación de prueba a la imagen y convertirla en un tensor\n",
    "imag = test_transform(imagen).unsqueeze(0)\n",
    "\n",
    "# Hacer una predicción con el modelo utilizando la imagen transformada\n",
    "with torch.no_grad():\n",
    "    pred = modelo(imag.to(dispositivo))\n",
    "    result = torch.softmax(pred, dim=1)[0]\n",
    "    indice = torch.argmax(result)\n",
    "    result = result[indice] * 100\n",
    "    \n",
    "    # Mostrar la imagen y la clasificación resultante\n",
    "    imagen.resize((192, 192)).show()\n",
    "    print(f\"{'pizza' if indice==1 else 'not pizza'} - {result:.2f}%\")\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neuronas\n",
    "\n",
    "Las neuronas son la unidad básica de procesamiento de la información en el cerebro. Una neurona recibe señales de entrada a través de las dendritas y las procesa. Si la señal de entrada es lo suficientemente fuerte, la neurona dispara una señal de salida a lo largo del axón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Estructura de una neurona\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:640/0*yV-rEh63sjNPIfrR\" alt=\"Mcpits\"  >\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Dendritas:** Las dendritas son estructuras en forma de árbol que reciben información a través de conexiones sinápticas. Esta información puede ser sensorial o “computacional” y proviene de otras células nerviosas. Una sola célula puede tener hasta 100,000 entradas, cada una de una célula diferente.\n",
    "- **Cuerpo celular:** El cuerpo celular o soma contiene el núcleo de la célula y procesa las señales de entrada de las dendritas.\n",
    "- **Axón:** El axón es una fibra larga que transmite señales de salida a otras neuronas a través de ramas llamadas terminales axónicas.\n",
    "- **Terminales axónicas:** Las terminales axónicas son ramas del axón que se ramifican en forma de árbol y transmiten señales de salida a otras neuronas a través de conexiones sinápticas.\n",
    "- **Sinapsis:** Las sinapsis son conexiones entre terminales axónicas y dendritas de otras neuronas. Las señales de salida de una neurona se transmiten a las dendritas de otras neuronas a través de las sinapsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neuronas artificiales\n",
    "\n",
    "Las neuronas artificiales son modelos matemáticos o computacionales que se inspiran en las neuronas biológicas, pero que se simplifican enormemente. Las neuronas artificiales son la unidad básica de procesamiento de las redes neuronales artificiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Estructura de una neurona artificial\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://jontysinai.github.io/assets/article_images/2017-11-11-the-perceptron/bio-vs-MCP.png\" alt=\"Mcpits\"  >\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Entradas  : Cada neurona recibe una serie de entradas que representan la información que ingresa al sistema. Estas entradas pueden ser características o variables relevantes para el problema que se está abordando.\n",
    "\n",
    "- Pesos : Cada entrada tiene asociado un peso que indica su importancia relativa en la neurona. Los pesos pueden ser considerados como los \"coeficientes\" que ponderan la influencia de cada entrada en la salida de la neurona. Los pesos pueden ajustarse durante el proceso de entrenamiento de la red neuronal para lograr un mejor rendimiento.\n",
    "\n",
    "- Sesgo : El sesgo es un parámetro adicional que se utiliza para ajustar la salida de la neurona. El sesgo es similar a un peso, pero no está asociado a ninguna entrada en particular. \n",
    "\n",
    "- Función de activación : Después de aplicar una combinación lineal de las entradas ponderadas por los pesos, se aplica una función de activación no lineal. Esta función introduce no linealidades en la neurona, lo que le permite capturar relaciones más complejas y realizar una transformación no lineal de los datos de entrada.  \n",
    "\n",
    "- La salida  de la neurona se calcula aplicando la función de activación a la suma ponderada de las entradas. Dependiendo del tipo de neurona o del contexto de la red neuronal, la salida de la neurona puede ser utilizada como entrada para otras neuronas o como salida final de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Funciones de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Función Sigmoide (Sigmoid)\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://hvidberrrg.github.io/deep_learning/activation_functions/assets/sigmoid_function.png\" alt=\"Mcpits\"  >\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esta función toma un valor real como entrada y devuelve una probabilidad que siempre está entre 0 y 1. La fórmula es f(x) = 1 / (1 + exp(-x)). Su rango de salida es [0, 1]. Una de las características de esta función es que presenta saturación de gradientes para valores extremadamente grandes o pequeños."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Función ReLU (Rectified Linear Unit)\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://images.deepai.org/glossary-terms/rectified-linear-units-1149176.jpg\" alt=\"Mcpits\"  >\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esta función devuelve el máximo entre 0 y el valor de entrada. La fórmula es f(x) = max(0, x). Su rango de salida es [0, +inf]. Una de las características de esta función es que no presenta saturación de gradientes en la región positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Función Leaky ReLU\n",
    " \n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://pic4.zhimg.com/80/v2-b30581f4f198f620340d981ae7c4689b_1440w.webp\" alt=\"Mcpits\"  >\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esta función es similar a la función ReLU, pero permite un pequeño valor negativo cuando la entrada es negativa. La fórmula es f(x) = max(ax, x), donde ‘a’ es un valor pequeño (por ejemplo, 0.01). Su rango de salida es (-inf, +inf). Una de las características de esta función es que resuelve el problema de la “neurona muerta” en ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Función Tanh (Tangente hiperbólica)\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://static.packt-cdn.com/products/9781838646301/graphics/assets/baaa8e5a-1d75-47f4-aef9-120f57f7c78c.png\" alt=\"Mcpits\"  >\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esta función toma un valor real como entrada y devuelve un valor entre -1 y 1. La fórmula es f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x)). Su rango de salida es [-1, 1]. Una de las características de esta función es que es similar a la función sigmoide pero con un rango de salida centrado en 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Función Identidad (Linear)\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://d1u2r2pnzqmal.cloudfront.net/content_images/images/113/normal/functions-and-realations-rfunction-two.jpg?1503310286\" alt=\"Mcpits\"  >\n",
    "</div> \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Esta función devuelve el valor de entrada sin cambios. La fórmula es f(x) = x. Su rango de salida es (-inf, +inf). Una de las características de esta función es que se utiliza en modelos lineales y regresiones para obtener salidas continuas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redes neuronales artificiales\n",
    " \n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:640/0*CXuqagS3-m4bHQss\" alt=\"Mcpits\"  >\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Las redes neuronales artificiales (ANN) son un modelo computacional que trata de emular el cerebro humano mediante una combinación de ciencia informática y estadística para resolver problemas comunes en el campo de la inteligencia artificial (IA). Están formadas por capas de nodos, que contienen una capa de entrada, una o varias capas ocultas y una capa de salida. Cada nodo, o neurona artificial, se conecta a otro y tiene un peso y un umbral asociados. Si la salida de un nodo individual está por encima del valor de umbral especificado, dicho nodo se activa y envía datos a la siguiente capa de la red.\n",
    "\n",
    "[Play Ground](https://playground.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/ejemploderetneuronalperroygatos.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Arquitecturas\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/arquitecturas.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La arquitectura de una red neuronal es la estructura y organización de sus componentes, es decir, cómo están dispuestas las capas y conexiones entre ellas.\n",
    "\n",
    "La arquitectura está determinada por:\n",
    "\n",
    "- Capas: Una red neuronal está compuesta por una o más capas de neuronas. Estas capas son unidades funcionales que procesan la información. Se organizan de forma secuencial, y la información fluye en una dirección desde la capa de entrada hasta la capa de salida.\n",
    "\n",
    "- Neuronas: Las neuronas son las unidades básicas de procesamiento en una red neuronal. Cada neurona toma una entrada, realiza una operación matemática y produce una salida. Las salidas de las neuronas se envían como entradas a las neuronas de la siguiente capa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Conexiones: Las conexiones son los enlaces que conectan las neuronas entre diferentes capas. Cada conexión tiene un peso asociado que determina la importancia de la información que se transmite de una neurona a otra.\n",
    "\n",
    "- Funciones de Activación: Cada neurona tiene asociada una función de activación que introduce no linealidades en el modelo. Al aplicar una función de activación a la salida de una neurona, se introduce la capacidad de aprender relaciones no lineales en los datos.\n",
    "\n",
    "- Tamaño de la Red: El número de neuronas y capas en la red determina su tamaño. Las redes más grandes, con más capas y neuronas, pueden aprender representaciones más complejas y resolver problemas más complejos, pero también pueden requerir más datos y recursos computacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Perceptrón\n",
    " \n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/perceptronderosenblank.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El perceptrón, desarrollado por Frank Rosenblatt en 1957, representa la forma más elemental de una red neuronal artificial, consistiendo en una única neurona. El perceptrón es un clasificador binario que toma un vector de entrada y produce una salida binaria, esto se debe a su función de activación, la cual es una función escalón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Redes Neuronales Feedforward\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/redneuronalfeedforward.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Las Redes Neuronales Feedforward son un tipo de arquitectura que consta de una capa de entrada, una capa de salida y una o más capas ocultas. Aunque también se les conoce como perceptrones multicapa (MLP), es esencial destacar que están formadas por neuronas sigmoideas en lugar de perceptrones, lo que les permite un mejor procesamiento de problemas no lineales. Estas redes neuronales feedforward tienen diversas aplicaciones, incluyendo la visión artificial, el procesamiento del lenguaje natural y otras tareas similares. Gracias a su capacidad para aprender y representar relaciones no lineales en los datos, se han convertido en una poderosa herramienta en el campo de la inteligencia artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Redes Neuronales Recurrentes (RNN)\n",
    " \n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/redneuronalrecurrente.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Las Redes Neuronales Recurrentes (RNN) se caracterizan por su estructura de bucles de retroalimentación. Estas redes neuronales son especialmente adecuadas para tareas que implican secuencias temporales u ordenadas, como predecir resultados futuros, como pronósticos del mercado de valores o ventas en cadenas de tiendas. Además de su aplicabilidad en pronósticos, las RNN también han demostrado un excelente rendimiento en tareas como la traducción de idiomas, el procesamiento del lenguaje natural (NLP) y el reconocimiento de voz. Su versatilidad y capacidad para manejar contextos secuenciales las han llevado a formar parte de aplicaciones como Siri y Google Translate, impulsando así la calidad y la eficiencia de estas herramientas de asistencia y traducción. Gracias a sus bucles de retroalimentación, las RNN pueden recordar información pasada y adaptarse a las características cambiantes en datos secuenciales, lo que las convierte en una poderosa opción para tareas temporales y ordenadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Redes neuronales convolucionales (ConvNets o CNN)\n",
    " \n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/convnet.jpeg?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Son un tipo especializado de red neuronal utilizado principalmente para el análisis de imágenes visuales. En lugar de la multiplicación de matrices general, utilizan la operación de convolución en al menos una de sus capas. Están específicamente diseñadas para procesar datos de píxeles y tienen diversas aplicaciones, como el reconocimiento y procesamiento de imágenes en tareas como clasificación, segmentación y análisis médico. Las CNN también se conocen como Redes Neuronales Artificiales Invariantes al Desplazamiento o al Espacio (SIANN) debido a su arquitectura de peso compartido, que proporciona respuestas equivariantes a la traducción, conocidas como mapas de características. En comparación con los perceptrones multicapa, las CNN abordan el sobreajuste aprovechando la jerarquía de patrones en los datos y ensamblan patrones complejos a partir de patrones más simples. Esto permite que la red aprenda representaciones abstractas de la entrada al procesar características en regiones más pequeñas y simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Variational Autoencoder (VAE)\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/autoencoder_orig.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un VAE (Variational Autoencoder) es una arquitectura de red neuronal que pertenece a la familia de modelos gráficos probabilísticos y métodos bayesianos variacionales. Es una extensión del autoencoder tradicional, que busca aprender una representación compacta y útil de los datos en un espacio latente de menor dimensión. Sin embargo, a diferencia del autoencoder, el VAE regulariza la distribución del espacio latente durante el entrenamiento para que siga una distribución específica, generalmente una distribución normal multivariante. Esto permite que el VAE genere nuevos datos al muestrear puntos en el espacio latente y decodificarlos para producir nuevas salidas. En resumen, el VAE es una poderosa herramienta para la generación de datos a partir de una distribución latente controlada y ha encontrado aplicaciones en diversos campos, como la generación de imágenes, el modelado de lenguaje y la música."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### UNET\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/u-net-architecture-1024x682.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "UNET es una arquitectura de red neuronal desarrollada por Olaf Ronneberger et al. en 2015 para la segmentación de imágenes biomédicas en la Universidad de Friburgo, Alemania. Es ampliamente utilizado en tareas de segmentación semántica debido a su eficacia y su capacidad para aprender con menos muestras de entrenamiento.\n",
    " \n",
    "Una UNET se asemeja a una \"U\" e incluye cuatro bloques codificadores y cuatro bloques decodificadores conectados a través de un puente. El camino de contracción (codificadores) reduce las dimensiones espaciales a la mitad y aumenta el número de filtros en cada bloque codificador.\n",
    "\n",
    "UNET se introdujo originalmente en el trabajo \"U-Net: Redes convolucionales para la segmentación de imágenes biomédicas\" de Ronneberger et al. y consta de un camino de contracción y un camino expansivo, siguiendo la arquitectura típica de una red convolucional. Esta estructura de red ha demostrado ser efectiva para la segmentación precisa de imágenes biomédicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Transformer\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/transformer.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El Transformer es una arquitectura de aprendizaje profundo basada en el mecanismo de atención. Destaca por requerir menos tiempo de entrenamiento en comparación con arquitecturas recurrentes anteriores, como LSTM, y ha sido ampliamente utilizado para entrenar grandes modelos de lenguaje en conjuntos de datos extensos, como Wikipedia y Common Crawl, gracias a su procesamiento paralelo de secuencias de entrada.\n",
    "\n",
    "El modelo toma tokens de entrada tokenizados y, en cada capa, contextualiza cada token con otros tokens de entrada a través del mecanismo de atención. Aunque el modelo Transformer se introdujo en 2017, el mecanismo de atención fue propuesto previamente en 2014 para la traducción automática.\n",
    "\n",
    "El Transformer ha encontrado aplicaciones no solo en el procesamiento del lenguaje natural, sino también en la visión por computadora, audio y procesamiento multimodal. Además, ha dado lugar al desarrollo de sistemas pre-entrenados como GPT (transformadores pre-entrenados generativos) y BERT (Representaciones del codificador bidireccional a partir de transformadores). Su versatilidad y eficiencia han revolucionado el campo del aprendizaje profundo y han permitido avances significativos en diversas tareas de procesamiento de datos complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deep Learning\n",
    "\n",
    "<div class=\"imagen\">\n",
    "<img src=\"https://github.com/YoelPilier/AIASTS/blob/Kirino/neural/redneuronalvsredneuronalprofunda.png?raw=true\" alt=\"Mcpits\"  >\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Deep Learning (Aprendizaje Profundo) es una tecnica de Machine Learning Inteligencia Artificial que se centra en el entrenamiento de redes neuronales artificiales profundas.El Deep Learning es capaz de aprender automáticamente representaciones de alto nivel y abstracciones a partir de los datos de entrada. Es impulsado por grandes cantidades de datos y el poder computacional necesario para entrenar modelos complejos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Entrenamiento de una red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### pytorch\n",
    "\n",
    "PyTorch es una biblioteca de aprendizaje automático de código abierto para Python, utilizada principalmente para el procesamiento del lenguaje natural. Fue desarrollado por los equipos de inteligencia artificial de Facebook Inc. en 2016.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Librerías\n",
    " \n",
    "  ```python\n",
    "!pip install safetensors torch\n",
    "\n",
    "\n",
    "  import torch\n",
    "  import torch.nn as nn\n",
    "  from safetensors.torch  import load_model,save_model\n",
    "\n",
    "  # Comprobamos si CUDA (tarjeta gráfica) está disponible en el sistema.\n",
    "  # Si CUDA está disponible, asignamos el dispositivo \"cuda\" a la variable 'device',\n",
    "  # de lo contrario, asignamos el dispositivo \"cpu\".\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "  ```\n",
    "\n",
    "  Con PyTorch podemos utilizar tanto la CPU como el GPU. Sin embargo, al elegir uno, debemos configurar todo el código para que utilice el mismo dispositivo. Para lograr esto, utilizaremos la variable device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Definir los datos de entrada y salida para el modelo\n",
    "\n",
    "```python\n",
    "\n",
    "x = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)\n",
    "\n",
    "y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float32)\n",
    "```\n",
    "  \n",
    "Para utilizar datos en PyTorch, ya sea para entrenamiento o inferencia, es necesario que los datos estén almacenados en tensores,un tensor es una estructura de datos similar a un arreglo multidimensional que puede contener elementos de varios tipos, pero para un correcto funcionamiento del modelo en PyTorch, se requiere que todos los tensores que representan los datos de entrada y salida sean del mismo tipo, y en este caso, deben ser del tipo torch.float32. Esto garantiza la consistencia en los cálculos y evita errores durante el proceso de entrenamiento e inferencia. Además, los tensores también permiten el cómputo acelerado en GPU si se tiene disponible una tarjeta gráfica compatible con CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Definir el modelo\n",
    "\n",
    "```python\n",
    "class RedNeuronal(nn.Module):\n",
    "  def __init__(self ):\n",
    "    # Inicializamos la clase padre\n",
    "    super(RedNeuronal, self).__init__()\n",
    "    # Definimos la arquitectura de la red neuronal\n",
    "    self.capa1=nn.Linear(2,2)\n",
    "    self.capa2=nn.Linear(2,1)\n",
    "    self.sigmoid=nn.Sigmoid()\n",
    "    self.relu=nn.ReLU()\n",
    "      \n",
    "    # Definimos el método para la propagación hacia adelante\n",
    "  def forward(self, x):\n",
    "    x=self.capa1(x)\n",
    "    x=self.relu(x)\n",
    "    x=self.capa2(x)\n",
    "    x=self.sigmoid(x)\n",
    "    return x\n",
    "```\n",
    "\n",
    "Para definir una red neuronal, debemos crear una clase que herede de la clase `nn.Module`. En esta clase, definimos las capas que compondrán el modelo, las funciones de activación y la función `forward`, que define cómo viajará la información a través del modelo. Esta función `forward` se utilizará tanto para el entrenamiento como para la inferencia cuando el modelo sea puesto en producción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Crear el modelo\n",
    "\n",
    "```python\n",
    "# Creamos una instancia de la clase RedNeuronal\n",
    "modelo = RedNeuronal()\n",
    "# Enviamos el modelo al dispositivo seleccionado\n",
    "modelo.to(device)\n",
    "print(modelo)\n",
    "```\n",
    "\n",
    "Para crear una instancia de la clase RedNeuronal, simplemente llamamos a la clase y asignamos la instancia a la variable model. Luego, enviamos el modelo al dispositivo seleccionado, ya sea CPU o GPU, utilizando el método to()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Definir hyperparámetros\n",
    "\n",
    "```python\n",
    "# Definimos el número de épocas\n",
    "epocas=50\n",
    "# Definimos la tasa de aprendizaje\n",
    "tasa_aprendizaje=3e-2\n",
    "  \n",
    "```\n",
    "\n",
    "Los hiperparámetros son parámetros externos que se utilizan para configurar un algoritmo de aprendizaje automático o una red neuronal antes del proceso de entrenamiento. A diferencia de los parámetros del modelo, que son ajustados internamente durante el proceso de entrenamiento para adaptarse a los datos, los hiperparámetros se establecen antes del entrenamiento y no cambian durante el proceso de aprendizaje. En este caso tenemos el numero de epocas que es la cantidad de veces que el modelo va a ver los datos de entrenamiento, y la tasa de aprendizaje que es la cantidad de ajuste que se le va a dar a los pesos en cada iteración.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Definir la función de pérdida y el optimizador\n",
    "\n",
    "```python\n",
    "# Definimos la función de pérdida\n",
    "funcion_perdida=nn.MSELoss()\n",
    "# Definimos el optimizador\n",
    "optimizador=torch.optim.Adam(modelo.parameters(), lr=tasa_aprendizaje)\n",
    "\n",
    "# Definimos las listas para almacenar las métricas de entrenamiento\n",
    "\n",
    "perdidas_train=[]\n",
    "\n",
    "Acuracy_train=[]\n",
    "\n",
    "error_train=[]\n",
    "```\n",
    "\n",
    "La función de pérdida es una medida que nos indica la discrepancia entre las predicciones del modelo y los valores reales de los datos de entrenamiento. El objetivo del optimizador es ajustar los pesos del modelo durante el proceso de entrenamiento para minimizar esta función de pérdida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Entrenar el modelo\n",
    "\n",
    "```python\n",
    "#Definimos el ciclo de entrenamiento\n",
    "# Iteramos sobre el número de épocas\n",
    "\n",
    "for epoca in range(epocas):\n",
    "  \n",
    "  # Reiniciamos los gradientes\n",
    "  optimizador.zero_grad()\n",
    "  # Hacemos la propagación hacia adelante\n",
    "  \n",
    "  x=x.to(device)\n",
    "  y=y.to(device)\n",
    "  y_pred=modelo(x)\n",
    "  # Calculamos la pérdida\n",
    "  perdida=funcion_perdida(y_pred, y)\n",
    "  # Hacemos la propagación hacia atrás\n",
    "  perdida.backward()\n",
    "  # Actualizamos los pesos\n",
    "  optimizador.step()\n",
    "  \n",
    "  # Guardamos la pérdida\n",
    "  \n",
    "  perdidas_train.append(perdida.item())\n",
    "  \n",
    "  # Calculamos el error\n",
    "  \n",
    "  error_train.append(torch.mean(torch.abs(y_pred-y)).item())\n",
    "  \n",
    "  # Calculamos el acuracy\n",
    "  \n",
    "  Acuracy_train.append(torch.mean((y_pred.round()==y).float()).item())\n",
    "  \n",
    "  # Imprimimos los resultados cada 10 épocas\n",
    "  \n",
    "  if (epoca+1)%10==0:\n",
    "    \n",
    "    print(f'Época: {epoca+1} - Pérdida: {perdida.item()} - Error: {error_train[-1]} - Acuracy: {Acuracy_train[-1]}')\n",
    "  \n",
    "```\n",
    "\n",
    "El proceso de entrenamiento de una red neuronal consiste en iterar sobre los datos de entrenamiento.En cada iteración, se realizan los siguientes pasos:\n",
    "\n",
    "- Se reinician los gradientes del optimizador para evitar acumulación en el cálculo del gradiente.\n",
    "- Se realiza la propagación hacia adelante pasando los datos de entrada (x) por el modelo para obtener las predicciones (y_pred).\n",
    "- Se calcula la pérdida (diferencia entre las predicciones y los valores reales, y) utilizando la función de pérdida definida anteriormente (funcion_perdida).\n",
    "- Se realiza la propagación hacia atrás (backpropagation) para calcular los gradientes de los pesos del modelo con respecto a la pérdida.\n",
    "- Se actualizan los pesos del modelo utilizando el optimizador (optimizador.step()) para minimizar la pérdida en la siguiente iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graficas\n",
    "\n",
    "```python\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Graficamos la pérdida, el error y la precisión durante el entrenamiento\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 12))\n",
    "\n",
    "axs[0].plot(perdidas_train)\n",
    "axs[0].set_title(\"Pérdida durante el entrenamiento\")\n",
    "axs[0].set_xlabel(\"Época\")\n",
    "axs[0].set_ylabel(\"Pérdida\")\n",
    "\n",
    "axs[1].plot(error_train)\n",
    "axs[1].set_title(\"Error durante el entrenamiento\")\n",
    "axs[1].set_xlabel(\"Época\")\n",
    "axs[1].set_ylabel(\"Error\")\n",
    "\n",
    "axs[2].plot(Acuracy_train)\n",
    "axs[2].set_title(\"Precisión durante el entrenamiento\")\n",
    "axs[2].set_xlabel(\"Época\")\n",
    "axs[2].set_ylabel(\"Precisión\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Evaluar el modelo\n",
    "\n",
    "  ```python \n",
    "    with torch.no_grad():\n",
    "    y_pred=modelo(x)\n",
    "    y_pred_clase=y_pred.round()\n",
    "    print(y_pred_clase)\n",
    "  ```\n",
    "  \n",
    "  Para evaluar el modelo, simplemente pasamos los datos de entrada (x) por el modelo para obtener las predicciones (y_pred). Luego, redondeamos las predicciones (y_pred_clase) para obtener la clase predicha (0 o 1) y la imprimimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Guardar el modelo\n",
    "\n",
    "```python\n",
    "    # Guardamos el modelo\n",
    "save_model(modelo, \"modelo.safetensors\")\n",
    "\n",
    "```\n",
    "\n",
    "##### Cargar el modelo\n",
    "\n",
    "```python\n",
    "    # Cargamos el modelo \n",
    "modelo=RedNeuronal()\n",
    "load_model(modelo, \"modelo.safetensors\")\n",
    "modelo.eval()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Inferencia\n",
    "\n",
    "```python\n",
    "def XOR(evaluar):\n",
    "    \n",
    "    evaluar=torch.tensor([evaluar],dtype=torch.float32)\n",
    "    evaluar=modelo(evaluar)\n",
    "    evaluar=evaluar.item()\n",
    "    return evaluar\n",
    "\n",
    "print(XOR([1,0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otros problemas de clasificación\n",
    "\n",
    "\n",
    "- AND\n",
    "- OR\n",
    "- XOR\n",
    "- NOT\n",
    "- XNOR\n",
    "- NOR\n",
    "- NAND\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
